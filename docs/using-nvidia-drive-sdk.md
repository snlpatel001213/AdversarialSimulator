# Using Nvidia DRIVE SDK



NVIDIA DRIVE™ Perception enables the robust perception of obstacles, paths, and wait conditions \(such as stop signs and traffic lights\) right out of the box with an extensive set of pre-processing, post-processing, and fusion processing modules. Together with NVIDIA DRIVE™ Networks, these form an end-to-end perception pipeline for autonomous driving that uses data from multiple sensor types \(e.g. camera, radar, LIDAR\). DRIVE Perception makes it possible for developers to create new perception, sensor fusion, mapping, and/or planning/control/actuation autonomous vehicle \(AV\) functionalities without having to first develop and validate the underlying perception building blocks.  
  


**DRIVE Perception** is designed for a variety of objectives:

* Developing perception algorithms for obstacles, path, and wait conditions
* Detecting and classifying objects, drivable space, lanes and road markings, and traffic lights and signs
* Tracking detected objects \(such as other vehicles, pedestrians, road markings\) from across frames
* Estimating distances to detected objects
* Fusing inputs from sensors of different modalities

Nvidia Drive Example App : 

Compiling Nvidia Drive Net

Finding sample:

```text

```

Re-compilation:

```text

```

Processing video frames:



Modifying sample to process Image frames



Predictions

